name: Terraform CI/CD

on:
  push:
    branches: main
    paths:
      - '**.tf'
      - '.github/workflows/terraform-cicd.yml'
  pull_request:
    branches: main
    paths:
      - '**.tf'
  workflow_dispatch:
    inputs:
      environment:
        description: 'Environment to deploy to'
        required: true
        default: 'dev'
        type: choice
        options:
          - dev
          - staging
          - prod

env:
  AWS_REGION: us-east-1
  PROJECT_NAME: bedrock-analytics-pipeline
  ENV: dev

permissions:
  id-token: write
  contents: read
  pull-requests: write

jobs:
  validate:
    name: Validate Terraform
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.5.0

      - name: Terraform Format Check
        run: |
          echo "Checking Terraform formatting..."
          if ! terraform fmt -check -recursive; then
            echo "âŒ Terraform files are not properly formatted"
            echo "Run 'terraform fmt -recursive' locally to fix formatting issues"
            exit 1
          else
            echo "âœ… All Terraform files are properly formatted"
          fi
      
      # FIX: Initialize with modules but without backend
      - name: Terraform Init (No Backend)
        run: |
          echo "ðŸ”§ Initializing Terraform without backend..."
          # Create a temporary backend configuration that doesn't require AWS credentials
          cat > backend_override.tf << EOF
          terraform {
            backend "local" {}
          }
          EOF
          
          terraform init -input=false
          echo "âœ… Terraform initialized with modules"

      - name: Terraform Validate
        run: |
          echo "ðŸ” Validating Terraform configuration..."
          terraform validate
          echo "âœ… Terraform validation successful"

      # Clean up temporary backend file
      - name: Cleanup
        run: rm -f backend_override.tf

  plan:
    name: Terraform Plan
    needs: validate
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.5.0

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: arn:aws:iam::${{ secrets.AWS_ACCOUNT_ID }}:role/GitHubActionsRole
          aws-region: ${{ env.AWS_REGION }}

      - name: Verify AWS Connection
        run: |
          echo "ðŸ” Verifying AWS connection..."
          aws sts get-caller-identity
          echo "âœ… AWS connection verified"

      # FIX: Proper Terraform initialization with backend
      - name: Terraform Init
        run: |
          echo "ðŸ”§ Initializing Terraform with backend..."
          terraform init -input=false
          echo "âœ… Terraform initialized with backend and modules"

      - name: Debug Environment
        run: |
          echo "ðŸ” Environment debugging..."
          ENV=${{ github.event.inputs.environment || env.ENV }}
          echo "Target environment: $ENV"
          echo "Available environment files:"
          find . -name "*.tfvars" -type f || echo "No .tfvars files found"
        
          # FIX: Proper bash syntax for file existence check
          if [ -f "environments/$ENV.tfvars" ]; then
            echo "ðŸ“„ Contents of environments/$ENV.tfvars:"
            cat environments/$ENV.tfvars
          else
            echo "âš ï¸ No tfvars file found for environment: $ENV"
          fi
          
      - name: Import Existing Resources with Validation
        run: |
          echo "ðŸ“¥ Starting resource import process..."
          
          AWS_ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)
          ENV=${{ github.event.inputs.environment || env.ENV }}
          
          # Enhanced import function with validation
          import_with_validation() {
            local resource_address=$1
            local resource_id=$2
            local resource_name=$3
            local aws_check_command=$4
            
            echo "ðŸ” Checking if $resource_name exists in AWS..."
            
            # Check if resource exists in AWS first
            if eval "$aws_check_command" >/dev/null 2>&1; then
              echo "âœ… $resource_name found in AWS"
              
              # Check if already in Terraform state
              if terraform state show "$resource_address" >/dev/null 2>&1; then
                echo "â„¹ï¸  $resource_name already in Terraform state"
              else
                echo "ðŸ”„ Importing $resource_name into Terraform state..."
                if terraform import "$resource_address" "$resource_id"; then
                  echo "âœ… Successfully imported $resource_name"
                else
                  echo "âŒ Failed to import $resource_name"
                  return 1
                fi
              fi
            else
              echo "âš ï¸  $resource_name not found in AWS - will be created"
            fi
            echo ""
          }

          # Import QuickSight Data Source
          import_with_validation \
            "module.quicksight.aws_quicksight_data_source.athena_source" \
            "$AWS_ACCOUNT_ID/bedrock-analytics-${ENV}-athena-source" \
            "QuickSight Data Source" \
            "aws quicksight describe-data-source --aws-account-id $AWS_ACCOUNT_ID --data-source-id bedrock-analytics-${ENV}-athena-source"

          # Import QuickSight Dataset (if exists)
          import_with_validation \
            "module.quicksight.aws_quicksight_data_set.bedrock_metrics_dataset" \
            "$AWS_ACCOUNT_ID/bedrock-analytics-${ENV}-metrics-4cdece83" \
            "QuickSight Dataset" \
            "aws quicksight describe-data-set --aws-account-id $AWS_ACCOUNT_ID --data-set-id bedrock-analytics-${ENV}-metrics-4cdece83"

          # Import S3 Bucket
          import_with_validation \
            "module.athena.aws_s3_bucket.athena_results" \
            "bedrock-analytics-${ENV}-metrics" \
            "S3 Bucket" \
            "aws s3api head-bucket --bucket bedrock-analytics-${ENV}-metrics"

          # Import Athena Workgroup
          import_with_validation \
            "module.athena.aws_athena_workgroup.bedrock_analytics" \
            "bedrock-analytics-${ENV}-workgroup" \
            "Athena Workgroup" \
            "aws athena get-work-group --work-group bedrock-analytics-${ENV}-workgroup"

          echo "ðŸŽ‰ Import process completed successfully"
        continue-on-error: true
      
      - name: Terraform Plan
        id: plan
        timeout-minutes: 10
        run: |
          set -e

          ENV=${{ github.event.inputs.environment || env.ENV }}

          # Add debug output
          export TF_LOG=INFO

          # FIX: Proper bash syntax for file existence check
          if [ -f "environments/$ENV.tfvars" ]; then
            echo "âœ… Using tfvars file: environments/$ENV.tfvars"

            terraform plan \
              -input=false \
              -var-file=environments/$ENV.tfvars \
              -out=tfplan \
              -detailed-exitcode \
              -lock-timeout=5m \
              -parallelism=10
          else
            echo "âš ï¸ Using default values (no tfvars file)"

            terraform plan \
              -input=false \
              -out=tfplan \
              -detailed-exitcode \
              -lock-timeout=5m \
              -parallelism=10
          fi

          # Capture exit code
          PLAN_EXIT_CODE=$?
          echo "Plan exit code: $PLAN_EXIT_CODE"
          echo "plan_exit_code=$PLAN_EXIT_CODE" >> $GITHUB_OUTPUT

          # Generate JSON output
          echo "ðŸ“Š Generating plan JSON..."
          terraform show -json tfplan > plan.json

          echo "âœ… Plan completed successfully"

      - name: Handle Plan Failures
        if: failure()
        run: |
          echo "âŒ Plan failed, attempting diagnostics..."

          # Check for common issues
          echo "ðŸ” Checking for state lock..."
          terraform plan 2>&1 | grep -i "lock" || echo "No lock issues detected"

          echo "ðŸ” Checking provider issues..."
          terraform providers

          echo "ðŸ” Checking AWS permissions..."
          aws iam get-role --role-name GitHubActionsRole || echo "Cannot access GitHubActionsRole"

          # Try to get more detailed error information
          echo "ðŸ” Detailed error output:"
          terraform plan -input=false 2>&1 | tail -20

      - name: Create Plan Summary
        run: |
          echo "### Terraform Plan Summary" > plan_summary.md
          echo '```' >> plan_summary.md
          terraform show -no-color tfplan | head -50 >> plan_summary.md || true
          echo '```' >> plan_summary.md

      - name: Upload Plan Summary
        uses: actions/upload-artifact@v4
        with:
          name: terraform-plan-summary
          path: plan_summary.md

      - name: Upload Plan
        uses: actions/upload-artifact@v4
        with:
          name: terraform-plan
          path: tfplan

      - name: Comment Plan on PR
        uses: actions/github-script@v7
        if: github.event_name == 'pull_request'
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const fs = require('fs');
            try {
              const planSummary = fs.readFileSync('plan_summary.md', 'utf8');
              await github.rest.issues.createComment({
                issue_number: context.issue.number,
                owner: context.repo.owner,
                repo: context.repo.repo,
                body: planSummary
              });
            } catch (error) {
              console.error('Error posting comment:', error);
            }

  apply:
    name: Terraform Apply
    needs: plan
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main' || github.event_name == 'workflow_dispatch'
    environment: ${{ github.event.inputs.environment || 'dev' }}
    timeout-minutes: 30
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.5.0

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: arn:aws:iam::${{ secrets.AWS_ACCOUNT_ID }}:role/GitHubActionsRole
          aws-region: ${{ env.AWS_REGION }}

      - name: Download Plan
        uses: actions/download-artifact@v4
        with:
          name: terraform-plan

      - name: Terraform Init
        run: |
          echo "ðŸ”§ Initializing Terraform..."
          terraform init -input=false
          echo "âœ… Terraform initialized"

      # In your GitHub Actions workflow - add this step before terraform plan/apply
      # - name: Import Existing QuickSight Resources
      #   run: |
      #     echo "ðŸ“¥ Importing existing QuickSight resources..."
          
      #     # Get AWS Account ID
      #     AWS_ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)
          
      #     # Function to safely import resources
      #     import_resource() {
      #       local resource_address=$1
      #       local resource_id=$2
      #       local resource_name=$3
            
      #       echo "ðŸ”„ Attempting to import $resource_name..."
      #       echo "  Resource: $resource_address"
      #       echo "  ID: $resource_id"
            
      #       if terraform import "$resource_address" "$resource_id" 2>/dev/null; then
      #         echo "âœ… Successfully imported $resource_name"
      #       else
      #         echo "âš ï¸  Import failed for $resource_name (may already be imported or not exist)"
      #         # Check if resource exists in AWS
      #         case "$resource_name" in
      #           *"QuickSight Data Source"*)
      #             aws quicksight describe-data-source \
      #               --aws-account-id $AWS_ACCOUNT_ID \
      #               --data-source-id bedrock-analytics-dev-athena-source \
      #               --query 'DataSource.Status' --output text 2>/dev/null || echo "Resource not found in AWS"
      #             ;;
      #           *"QuickSight Dataset"*)
      #             aws quicksight describe-data-set \
      #               --aws-account-id $AWS_ACCOUNT_ID \
      #               --data-set-id bedrock-analytics-dev-metrics-4cdece83 \
      #               --query 'DataSet.DataSetId' --output text 2>/dev/null || echo "Resource not found in AWS"
      #             ;;
      #         esac
      #       fi
      #       echo ""
      #     }

      #     # Import QuickSight resources
      #     import_resource \
      #       "module.quicksight.aws_quicksight_data_source.athena_source" \
      #       "$AWS_ACCOUNT_ID/bedrock_analytics-dev-athena-source" \
      #       "QuickSight Data Source"
          
      #     import_resource \
      #       "module.quicksight.aws_quicksight_data_set.bedrock_metrics_dataset" \
      #       "$AWS_ACCOUNT_ID/bedrock-analytics-dev-metrics-4cdece83" \
      #       "QuickSight Dataset"
          
      #     # Import other resources as needed
      #     import_resource \
      #       "module.athena.aws_s3_bucket.athena_results" \
      #       "bedrock-analytics-dev-metrics" \
      #       "S3 Bucket"
          
      #     import_resource \
      #       "module.athena.aws_athena_workgroup.bedrock_analytics" \
      #       "bedrock-analytics-dev-workgroup" \
      #       "Athena Workgroup"

      #     echo "âœ… Import phase completed"
      #   continue-on-error: true

      - name: Terraform Apply
        timeout-minutes: 20
        run: |
          ENV=${{ github.event.inputs.environment || env.ENV }}
          echo "ðŸš€ Applying Terraform for environment: $ENV"

          # FIX: Proper bash syntax for file existence check
          if [ -f "environments/$ENV.tfvars" ]; then
            echo "âœ… Using tfvars file: environments/$ENV.tfvars"
            terraform apply -auto-approve -input=false -var-file=environments/$ENV.tfvars
          else
            echo "âš ï¸ No tfvars file found, applying with default values"
            terraform apply -auto-approve -input=false
          fi
          
          echo "âœ… Apply completed successfully"

      - name: Handle Apply Failures
        if: failure()
        run: |
          echo "âŒ Apply failed, running diagnostics..."
          
          # Show current state
          terraform state list || echo "No resources in state"
          
          # Show last few log entries
          echo "Recent Terraform output:"
          tail -50 terraform.log 2>/dev/null || echo "No terraform.log found"
          
          # Check AWS resources directly
          AWS_ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)
          aws quicksight describe-data-source --aws-account-id $AWS_ACCOUNT_ID --data-source-id bedrock-analytics-dev-athena-source 2>/dev/null || echo "QuickSight data source not found"