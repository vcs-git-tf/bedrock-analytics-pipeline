name: Terraform CI/CD

on:
  push:
    branches: [main]
    paths:
      - '**.tf'
      - '.github/workflows/terraform-cicd.yml'
  pull_request:
    branches: [main]
    paths:
      - '**.tf'
  workflow_dispatch:
    inputs:
      environment:
        description: 'Environment to deploy to'
        required: true
        default: 'dev'
        type: choice
        options:
          - dev
          - staging
          - prod

env:
  AWS_REGION: us-east-1
  PROJECT_NAME: bedrock-analytics-pipeline
  ENV: dev

permissions:
  id-token: write
  contents: read
  pull-requests: write

jobs:
  validate:
    name: Validate Terraform
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.5.0

      - name: Terraform Format Check
        run: |
          echo "Checking Terraform formatting..."
          if ! terraform fmt -check -recursive; then
            echo "âŒ Terraform files are not properly formatted"
            echo "Run 'terraform fmt -recursive' locally to fix formatting issues"
            exit 1
          else
            echo "âœ… All Terraform files are properly formatted"
          fi

      - name: Terraform Init Main
        run: terraform init -backend=false

      - name: Terraform Validate Main
        run: terraform validate

      - name: Terraform Format Check
        run: terraform fmt -check -recursive  

  plan:
    name: Terraform Plan
    needs: validate
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.5.0

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: arn:aws:iam::${{ secrets.AWS_ACCOUNT_ID }}:role/GitHubActionsRole
          aws-region: ${{ env.AWS_REGION }}

      - name: Verify AWS Connection
        run: |
          echo "ðŸ” Verifying AWS connection..."
          aws sts get-caller-identity
          echo "âœ… AWS connection verified"

      - name: Terraform Init
        run: |
          echo "ðŸ”§ Initializing Terraform..."
          terraform init -input=false
          echo "âœ… Terraform initialized"   

      # - name: Import Existing Resources
      #   run: |
      #     echo "ðŸ“¥ Importing existing resources..."
        
      #     AWS_ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)
        
      #     # Import with timeout and error handling
      #     timeout 300 terraform import module.athena.aws_s3_bucket.athena_results bedrock-analytics-dev-metrics || echo "S3 bucket import failed or already imported"
      #     timeout 300 terraform import module.athena.aws_athena_workgroup.bedrock_analytics bedrock-analytics-dev-workgroup || echo "Workgroup import failed or already imported"
      #     timeout 300 terraform import module.quicksight.aws_quicksight_data_source.athena_source $AWS_ACCOUNT_ID/bedrock-analytics-dev-athena-source || echo "Data source import failed or already imported"
        
      #     echo "âœ… Import phase completed"
      #   continue-on-error: true

      - name: Debug Environment
        run: |
          echo "ðŸ” Environment debugging..."
          ENV=${{ github.event.inputs.environment || env.ENV }}
          echo "Target environment: $ENV"
          echo "Available environment files:"
          find . -name "*.tfvars" -type f || echo "No .tfvars files found"
        
          if [ -f "environments/$ENV.tfvars" ]; then
            echo "ðŸ“„ Contents of environments/$ENV.tfvars:"
            cat environments/$ENV.tfvars
          fi    
      
      - name: Terraform Plan
        id: plan
        timeout-minutes: 10
        run: |
          set -e

          ENV=${{ github.event.inputs.environment || env.ENV }}

          # Add debug output
          export TF_LOG=INFO

          # Check if tfvars file exists (FIXED)
          if [ -f "environments/$ENV.tfvars" ]; then
            echo "âœ… Using tfvars file: environments/$ENV.tfvars"

            terraform plan \
              -input=false \
              -var-file=environments/$ENV.tfvars \
              -out=tfplan \
              -detailed-exitcode \
              -lock-timeout=5m \
              -parallelism=10
          else
            echo "âš ï¸  Using default values (no tfvars file)"

            terraform plan \
              -input=false \
              -out=tfplan \
              -detailed-exitcode \
              -lock-timeout=5m \
              -parallelism=10
          fi

          # Capture exit code
          PLAN_EXIT_CODE=$?
          echo "Plan exit code: $PLAN_EXIT_CODE"
          echo "plan_exit_code=$PLAN_EXIT_CODE" >> $GITHUB_OUTPUT

          # Generate JSON output
          echo "ðŸ“Š Generating plan JSON..."
          terraform show -json tfplan > plan.json

          echo "âœ… Plan completed successfully"

      - name: Handle Plan Failures
        if: failure()
        run: |
          echo "âŒ Plan failed, attempting diagnostics..."

          # Check for common issues
          echo "ðŸ” Checking for state lock..."
          terraform plan 2>&1 | grep -i "lock" || echo "No lock issues detected"

          echo "ðŸ” Checking provider issues..."
          terraform providers

          echo "ðŸ” Checking AWS permissions..."
          aws iam get-role --role-name GitHubActionsRole || echo "Cannot access GitHubActionsRole"

          # Try to get more detailed error information
          echo "ðŸ” Detailed error output:"
          terraform plan -input=false 2>&1 | tail -20

      - name: Create Plan Summary
        run: |
          echo "### Terraform Plan Summary" > plan_summary.md
          echo '```' >> plan_summary.md
          terraform show -no-color tfplan | head -50 >> plan_summary.md || true
          echo '```' >> plan_summary.md

      - name: Upload Plan Summary
        uses: actions/upload-artifact@v4
        with:
          name: terraform-plan-summary
          path: plan_summary.md

      - name: Upload Plan
        uses: actions/upload-artifact@v4
        with:
          name: terraform-plan
          path: tfplan

      - name: Comment Plan on PR
        uses: actions/github-script@v7
        if: github.event_name == 'pull_request'
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const fs = require('fs');
            try {
              const planSummary = fs.readFileSync('plan_summary.md', 'utf8');
              await github.rest.issues.createComment({
                issue_number: context.issue.number,
                owner: context.repo.owner,
                repo: context.repo.repo,
                body: planSummary
              });
            } catch (error) {
              console.error('Error posting comment:', error);
            }

  apply:
    name: Terraform Apply
    needs: plan
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main' || github.event_name == 'workflow_dispatch'
    environment: \${{ github.event.inputs.environment || '${ENV}' }}
    timeout-minutes: 30  # Add overall timeout
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.5.0

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: arn:aws:iam::${{ secrets.AWS_ACCOUNT_ID }}:role/GitHubActionsRole
          aws-region: ${{ env.AWS_REGION }}

      - name: Download Plan
        uses: actions/download-artifact@v4
        with:
          name: terraform-plan

      - name: Terraform Init
        run: terraform init -input=false

      - name: Import Existing Athena Resources
        run: |
          echo "ðŸ“¥ Importing existing resources..."
    
          # Get AWS Account ID
          AWS_ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)

          # Check QuickSight data source status first
          echo "ðŸ” Checking QuickSight data source status..."
          DATA_SOURCE_STATUS=$(aws quicksight describe-data-source \
            --aws-account-id $AWS_ACCOUNT_ID \
            --data-source-id bedrock-analytics-dev-athena-source \
            --query 'DataSource.Status' \
            --output text 2>/dev/null || echo "NOT_FOUND")

          echo "Data source status: $DATA_SOURCE_STATUS"

          # Handle based on status
          if [ "$DATA_SOURCE_STATUS" = "CREATION_FAILED" ]; then
            echo "âŒ Found failed data source, deleting..."
            aws quicksight delete-data-source \
              --aws-account-id $AWS_ACCOUNT_ID \
              --data-source-id bedrock-analytics-dev-athena-source || echo "Delete failed"
            echo "â³ Waiting for deletion to propagate..."
            sleep 30

          elif [ "$DATA_SOURCE_STATUS" = "CREATION_SUCCESSFUL" ]; then
            echo "âœ… Data source is healthy, importing..."
            terraform import module.quicksight.aws_quicksight_data_source.athena_source $AWS_ACCOUNT_ID/bedrock-analytics-dev-athena-source || echo "Import failed"
          fi
          
          # Function to safely import resources
          import_resource() {
          local resource_address=$1
          local resource_id=$2
          local resource_name=$3
          
          echo "ðŸ”„ Attempting to import $resource_name..."
          if terraform import "$resource_address" "$resource_id" 2>/dev/null; then
            echo "âœ… Successfully imported $resource_name"
          else
            echo "âš ï¸  Import failed for $resource_name (may already be imported or not exist)"
          fi
          }

          # Import all resources
          import_resource "module.athena.aws_s3_bucket.athena_results" "bedrock-analytics-dev-metrics" "S3 Bucket"
          import_resource "module.athena.aws_athena_workgroup.bedrock_analytics" "bedrock-analytics-dev-workgroup" "Athena Workgroup"
          import_resource "module.quicksight.aws_quicksight_data_source.athena_source" "$AWS_ACCOUNT_ID/bedrock-analytics-dev-athena-source" "QuickSight Data Source"
          import_resource "module.quicksight.aws_iam_role.quicksight_service_role" "bedrock-analytics-dev-quicksight-service-role" "QuickSight IAM Role"

          echo "âœ… Import phase completed"
        continue-on-error: true

      - name: Terraform Apply
        timeout-minutes: 20
        run: |
          ENV=${{ github.event.inputs.environment || env.ENV }}
          echo "ðŸš€ Applying Terraform for environment: $ENV"

          # FIXED: Proper bash syntax
          if [ -f "environments/$ENV.tfvars" ]; then
            echo "âœ… Using tfvars file: environments/$ENV.tfvars"
            terraform apply -auto-approve -input=false -var-file=environments/$ENV.tfvars
          else
            echo "âš ï¸  No tfvars file found, applying with default values"
            terraform apply -auto-approve -input=false
          fi

          echo "âœ… Apply completed successfully"

      - name: Handle Apply Failures
        if: failure()
        run: |
          echo "âŒ Apply failed, running diagnostics..."

          # Show current state
          terraform state list || echo "No resources in state"

          # Show last few log entries
          echo "Recent Terraform output:"
          tail -50 terraform.log 2>/dev/null || echo "No terraform.log found"

          # Check AWS resources directly
          AWS_ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)
          aws quicksight describe-data-source --aws-account-id $AWS_ACCOUNT_ID --data-source-id bedrock-analytics-dev-athena-source 2>/dev/null || echo "QuickSight data source not found"